from airflow.decorators import dag, task
from datetime import datetime, timedelta
import requests
import logging
import pytz
import time

KST = pytz.timezone('Asia/Seoul')
logger = logging.getLogger(__name__)

FLINK_GATEWAY_URL = "http://sql-gateway-service-20.flink.svc.cluster.local:8083"

@dag(
    dag_id='kafka_to_rds_streaming',
    description='Kafkaì—ì„œ RDSë¡œ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° (24/7 ì‹¤í–‰)',
    schedule=None,
    start_date=datetime(2025, 1, 1, tzinfo=KST),
    catchup=False,
    tags=['flink', 'streaming', 'kafka', 'rds'],
    default_args={
        'owner': 'airflow',
        'depends_on_past': False,
        'email_on_failure': False,
        'email_on_retry': False,
        'retries': 3,
        'retry_delay': timedelta(minutes=5),
    }
)
def kafka_to_rds_streaming():
    
    @task
    def read_sql_file():
        """Flink SQL íŒŒì¼ ì½ê¸°"""
        sql_file_path = "/opt/airflow/dags/repo/flink_sql/03_kafka_to_rds_streaming.sql"
        
        try:
            with open(sql_file_path, 'r', encoding='utf-8') as f:
                sql_content = f.read()
            
            logger.info(f"SQL íŒŒì¼ ì½ê¸° ì„±ê³µ: {sql_file_path}")
            logger.info(f"SQL ê¸¸ì´: {len(sql_content)} bytes")
            return sql_content
            
        except Exception as e:
            logger.error(f"SQL íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}")
            raise
    
    @task
    def submit_streaming_job(sql_content: str):
        """Flink Streaming Job ì œì¶œ (24/7 ì‹¤í–‰) - ì„¸ì…˜ ìƒì„±ë¶€í„° ì¢…ë£Œê¹Œì§€"""
        # 1. ì„¸ì…˜ ìƒì„±
        session_url = f"{FLINK_GATEWAY_URL}/v1/sessions"
        
        try:
            session_response = requests.post(session_url, json={
                "properties": {
                    "sql-gateway.session.idle-timeout": "365d",
                    "sql-gateway.session.check-interval": "24h"
                }
            }, timeout=10)
            session_response.raise_for_status()
            session_handle = session_response.json()['sessionHandle']
            logger.info(f"ì„¸ì…˜ ìƒì„± ì„±ê³µ (365d timeout): {session_handle}")
        except Exception as e:
            logger.error(f"ì„¸ì…˜ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            raise
        
        # 2. SQL ì‹¤í–‰
        url = f"{FLINK_GATEWAY_URL}/v1/sessions/{session_handle}/statements"
        
        # SQL êµ¬ë¬¸ ë¶„ë¦¬ (SET, CREATE, BEGIN...END ë¶„ë¦¬)
        statements = []
        current_statement = ""
        in_statement_set = False
        
        for line in sql_content.split('\n'):
            line = line.strip()
            
            # ì£¼ì„ ë¬´ì‹œ
            if line.startswith('--') or not line:
                continue
            
            current_statement += line + " "
            
            # EXECUTE STATEMENT SET ë˜ëŠ” BEGIN STATEMENT SET ê°ì§€
            if 'EXECUTE STATEMENT SET' in line.upper() or 'BEGIN STATEMENT SET' in line.upper():
                in_statement_set = True
            
            # END ê°ì§€
            if line.upper() == 'END;':
                statements.append(current_statement.strip())
                current_statement = ""
                in_statement_set = False
            # ì¼ë°˜ êµ¬ë¬¸ ì¢…ë£Œ
            elif line.endswith(';') and not in_statement_set:
                statements.append(current_statement.strip())
                current_statement = ""
        
        logger.info(f"ì´ {len(statements)}ê°œ SQL êµ¬ë¬¸ ì‹¤í–‰ ì˜ˆì •")
        
        # ê° êµ¬ë¬¸ ì‹¤í–‰
        for idx, statement in enumerate(statements):
            if not statement:
                continue
            
            try:
                logger.info(f"[{idx+1}/{len(statements)}] SQL ì‹¤í–‰ ì¤‘...")
                logger.info(f"SQL: {statement[:100]}...")
                
                response = requests.post(
                    url, 
                    json={"statement": statement},
                    timeout=300
                )
                response.raise_for_status()
                result = response.json()
                
                operation_handle = result.get('operationHandle')
                logger.info(f"[{idx+1}/{len(statements)}] ì‹¤í–‰ ì„±ê³µ: {operation_handle}")
                
                # STATEMENT SET (ìŠ¤íŠ¸ë¦¬ë° ì¡) ì‹¤í–‰ ì‹œ
                if 'EXECUTE STATEMENT SET' in statement.upper() or 'BEGIN STATEMENT SET' in statement.upper():
                    logger.info("âœ… ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° Job ì‹œì‘ë¨!")
                    logger.info("ğŸ“Š Kafka -> RDS ì‹¤ì‹œê°„ ì „ì†¡ í™œì„±í™”")
                    logger.info(f"ğŸ”‘ Session: {session_handle}")
                    logger.info(f"âš™ï¸ Operation: {operation_handle}")
                    
                    # 3. Job ìƒíƒœ ëª¨ë‹ˆí„°ë§ (1ë…„ê°„ ê³„ì† ì‹¤í–‰)
                    logger.info("â° ìŠ¤íŠ¸ë¦¬ë° Job ëª¨ë‹ˆí„°ë§ ì‹œì‘ (365ì¼ê°„ ì‹¤í–‰)")
                    logger.info("ğŸ›‘ Jobì„ ì¤‘ì§€í•˜ë ¤ë©´ Flink UIì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ì·¨ì†Œí•˜ì„¸ìš”")
                    
                    # Jobì´ ê³„ì† ì‹¤í–‰ë˜ë„ë¡ Taskë¥¼ ì‚´ë ¤ë‘  (365ì¼)
                    sleep_duration = 365 * 24 * 60 * 60  # 1ë…„
                    logger.info(f"ğŸ’¤ {sleep_duration}ì´ˆ ë™ì•ˆ ì„¸ì…˜ ìœ ì§€...")
                    
                    try:
                        time.sleep(sleep_duration)
                    except Exception as e:
                        logger.warning(f"âš ï¸ Sleep ì¤‘ë‹¨ë¨: {str(e)}")
                    
                    return {
                        'status': 'streaming_started',
                        'operation_handle': operation_handle,
                        'session': session_handle,
                        'message': 'Streaming job ran for 1 year'
                    }
                
            except Exception as e:
                logger.error(f"[{idx+1}/{len(statements)}] ì‹¤í–‰ ì‹¤íŒ¨: {str(e)}")
                if idx < len(statements) - 1:
                    logger.warning("ê³„ì† ì§„í–‰...")
                    continue
                else:
                    raise
        
        # 4. ì¼ë°˜ ì¢…ë£Œ (ìŠ¤íŠ¸ë¦¬ë°ì´ ì•„ë‹Œ ê²½ìš°)
        close_url = f"{FLINK_GATEWAY_URL}/v1/sessions/{session_handle}"
        try:
            requests.delete(close_url, timeout=10)
            logger.info(f"ì„¸ì…˜ ì¢…ë£Œ ì„±ê³µ: {session_handle}")
        except Exception as e:
            logger.warning(f"ì„¸ì…˜ ì¢…ë£Œ ì‹¤íŒ¨ (ë¬´ì‹œ): {str(e)}")
        
        return {'status': 'completed', 'statements_executed': len(statements), 'session': session_handle}
    
    # Task íë¦„
    sql_content = read_sql_file()
    result = submit_streaming_job(sql_content)
    
    return result

# DAG ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
dag_instance = kafka_to_rds_streaming()




